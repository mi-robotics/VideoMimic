{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dinov3_features():\n",
    "    \"\"\"\n",
    "    This function demonstrates how to extract image features using a pre-trained\n",
    "    DINOv3 model from the Hugging Face Hub.\n",
    "    \"\"\"\n",
    "    # --- 1. Set up the model and image processor ---\n",
    "    # We'll use a smaller, efficient version of DINOv3 for this demo.\n",
    "    model_name = \"facebook/dinov3-vits16\"\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "\n",
    "    # The AutoImageProcessor handles all the necessary transformations for the model,\n",
    "    # such as resizing, normalization, and converting the image to a tensor.\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "    # The AutoModel class loads the pre-trained DINOv3 model weights.\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    # Move the model to the GPU if available, for faster processing.\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    # --- 2. Load and prepare the image ---\n",
    "    # We'll use a sample image from the web.\n",
    "    url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "    print(f\"\\nLoading image from: {url}\")\n",
    "    try:\n",
    "        image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "        print(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return\n",
    "\n",
    "    # \n",
    "\n",
    "    # --- 3. Process the image and extract features ---\n",
    "    print(\"\\nProcessing image and extracting features...\")\n",
    "\n",
    "    # The image processor prepares the image in the format the model expects.\n",
    "    # `return_tensors=\"pt\"` ensures the output is a PyTorch tensor.\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # We run the model in inference mode, without calculating gradients.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # The primary output is the `last_hidden_state`.\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "\n",
    "    # --- 4. Understand the output features ---\n",
    "    print(\"\\n--- Feature Extraction Results ---\")\n",
    "\n",
    "    # The output tensor has the shape: [batch_size, num_tokens, embedding_dim]\n",
    "    print(f\"Shape of the output tensor: {last_hidden_state.shape}\")\n",
    "\n",
    "    # The first token is the [CLS] token, which represents the global features\n",
    "    # of the entire image. This is often used for image classification tasks.\n",
    "    cls_token = last_hidden_state[:, 0]\n",
    "    print(f\"Shape of the [CLS] (global) token: {cls_token.shape}\")\n",
    "\n",
    "    # The subsequent tokens are the patch tokens. DINOv3 divides the image into\n",
    "    # a grid of patches (e.g., 16x16 pixels) and creates a feature vector for each.\n",
    "    # These are useful for dense prediction tasks like segmentation.\n",
    "    patch_tokens = last_hidden_state[:, 1:]\n",
    "    print(f\"Shape of the patch tokens: {patch_tokens.shape}\")\n",
    "    print(\"\\nThis script has successfully extracted both global and patch-level features from the image using DINOv3.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
