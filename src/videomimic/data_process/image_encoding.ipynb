{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import cv2\n",
    "import torch\n",
    "from transformers.image_utils import load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2frames(vidfile, save_folder):\n",
    "    \"\"\" Convert input video to images \"\"\"\n",
    "    count = 0\n",
    "    cap = cv2.VideoCapture(vidfile)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imwrite(f'{save_folder}/{count:04d}.jpg', frame)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_example = '/home/milo/Documents/phd/VideoMimic/tram/example_video.mov'\n",
    "outpath = '/home/milo/Documents/phd/VideoMimic/src/videomimic/data/example'\n",
    "video2frames(vid_example, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049421e2b55c4c08b26368e02dae853f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dinov2_model():\n",
    "    processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "    model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "    return processor, model\n",
    "\n",
    "def extract_dinov2_features(images, processor, model):\n",
    "    inputs = processor(images=images, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    return last_hidden_states[:, 0, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dinov3_model():    \n",
    "    processor = AutoImageProcessor.from_pretrained(\"facebook/dinov3-vitl16-pretrain-lvd1689m\")\n",
    "    model = AutoModel.from_pretrained(\"facebook/dinov3-vitl16-pretrain-lvd1689m\")\n",
    "    return processor, model\n",
    "\n",
    "def extract_dinov3_features(images, processor, model):\n",
    "    inputs = processor(images=images, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    return last_hidden_states[:, 0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bb534ee54148b7b8be066a8c77cc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor, model = load_dinov2_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da5dada6b924f7a864db73b816f34da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dv3_processor, dv3_model = load_dinov3_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def benchmark_dinov3_inference(processor, model, image_paths, batch_sizes=[1, 2, 4, 8, 16], num_warmup=5, num_iterations=20):\n",
    "    \"\"\"\n",
    "    Benchmark DINOv3 inference speed with different batch sizes\n",
    "    \n",
    "    Args:\n",
    "        processor: DINOv3 image processor\n",
    "        model: DINOv3 model\n",
    "        image_paths: List of image paths to use for testing\n",
    "        batch_sizes: List of batch sizes to test\n",
    "        num_warmup: Number of warmup iterations\n",
    "        num_iterations: Number of timing iterations\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with timing results for each batch size\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    print(f\"Running on device: {device}\")\n",
    "    \n",
    "    # Load all images once\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        if os.path.exists(path):\n",
    "            image = load_image(path)\n",
    "            images.append(image)\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images for testing\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\nTesting batch size: {batch_size}\")\n",
    "        \n",
    "        # Prepare batches\n",
    "        batches = []\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch = images[i:i+batch_size]\n",
    "            batches.append(batch)\n",
    "        \n",
    "        if not batches:\n",
    "            print(f\"No batches created for batch size {batch_size}\")\n",
    "            continue\n",
    "            \n",
    "        # Warmup\n",
    "        print(f\"Warming up with {num_warmup} iterations...\")\n",
    "        for i in range(num_warmup):\n",
    "            batch = batches[i % len(batches)]\n",
    "            with torch.no_grad():\n",
    "                inputs = processor(images=batch, return_tensors=\"pt\").to(device)\n",
    "                outputs = model(**inputs)\n",
    "        \n",
    "        # Timing\n",
    "        print(f\"Running {num_iterations} timing iterations...\")\n",
    "        times = []\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            batch = batches[i % len(batches)]\n",
    "            \n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                inputs = processor(images=batch, return_tensors=\"pt\").to(device)\n",
    "                outputs = model(**inputs)\n",
    "                features = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "            end_time = time.time()\n",
    "            \n",
    "            inference_time = end_time - start_time\n",
    "            times.append(inference_time)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        times = np.array(times)\n",
    "        mean_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        fps = batch_size / mean_time\n",
    "        \n",
    "        results[batch_size] = {\n",
    "            'mean_time': mean_time,\n",
    "            'std_time': std_time,\n",
    "            'fps': fps,\n",
    "            'min_time': np.min(times),\n",
    "            'max_time': np.max(times)\n",
    "        }\n",
    "        \n",
    "        print(f\"Batch size {batch_size}:\")\n",
    "        print(f\"  Mean inference time: {mean_time:.4f}s ¬± {std_time:.4f}s\")\n",
    "        print(f\"  FPS: {fps:.2f}\")\n",
    "        print(f\"  Min time: {np.min(times):.4f}s\")\n",
    "        print(f\"  Max time: {np.max(times):.4f}s\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model moved to cuda\n",
      "GPU: NVIDIA GeForce RTX 5090\n",
      "GPU Memory: 33.6 GB\n",
      "Available GPU Memory: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and move model to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "dv3_model = dv3_model.to(device)\n",
    "print(f\"Model moved to {device}\")\n",
    "\n",
    "# Check GPU memory if available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"Available GPU Memory: {torch.cuda.memory_reserved(0) / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 247 images in /home/milo/Documents/phd/VideoMimic/src/videomimic/data/example\n",
      "  0: 0000.jpg\n",
      "  1: 0001.jpg\n",
      "  2: 0002.jpg\n",
      "  3: 0003.jpg\n",
      "  4: 0004.jpg\n"
     ]
    }
   ],
   "source": [
    "# Prepare test images - use the example video frames\n",
    "example_dir = '/home/milo/Documents/phd/VideoMimic/src/videomimic/data/example'\n",
    "image_paths = []\n",
    "\n",
    "if os.path.exists(example_dir):\n",
    "    # Get all jpg files from the example directory\n",
    "    for file in os.listdir(example_dir):\n",
    "        if file.endswith('.jpg'):\n",
    "            image_paths.append(os.path.join(example_dir, file))\n",
    "    \n",
    "    # Sort to ensure consistent ordering\n",
    "    image_paths.sort()\n",
    "    print(f\"Found {len(image_paths)} images in {example_dir}\")\n",
    "    \n",
    "    # Show first few paths\n",
    "    for i, path in enumerate(image_paths[:5]):\n",
    "        print(f\"  {i}: {os.path.basename(path)}\")\n",
    "else:\n",
    "    print(f\"Directory {example_dir} not found!\")\n",
    "    # Fallback: create a list with the single image we know exists\n",
    "    single_image = '/home/milo/Documents/phd/VideoMimic/src/videomimic/data/example/0000.jpg'\n",
    "    if os.path.exists(single_image):\n",
    "        image_paths = [single_image] * 10  # Duplicate for testing\n",
    "        print(f\"Using single image duplicated 10 times: {single_image}\")\n",
    "    else:\n",
    "        print(\"No test images found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DINOv3 INFERENCE SPEED BENCHMARK\n",
      "============================================================\n",
      "Running on device: cuda:0\n",
      "Loaded 247 images for testing\n",
      "\n",
      "Testing batch size: 1\n",
      "Warming up with 3 iterations...\n",
      "Running 10 timing iterations...\n",
      "Batch size 1:\n",
      "  Mean inference time: 0.0103s ¬± 0.0002s\n",
      "  FPS: 97.27\n",
      "  Min time: 0.0099s\n",
      "  Max time: 0.0107s\n",
      "\n",
      "Testing batch size: 2\n",
      "Warming up with 3 iterations...\n",
      "Running 10 timing iterations...\n",
      "Batch size 2:\n",
      "  Mean inference time: 0.0150s ¬± 0.0008s\n",
      "  FPS: 133.51\n",
      "  Min time: 0.0141s\n",
      "  Max time: 0.0172s\n",
      "\n",
      "Testing batch size: 4\n",
      "Warming up with 3 iterations...\n",
      "Running 10 timing iterations...\n",
      "Batch size 4:\n",
      "  Mean inference time: 0.0291s ¬± 0.0013s\n",
      "  FPS: 137.49\n",
      "  Min time: 0.0276s\n",
      "  Max time: 0.0324s\n",
      "\n",
      "Testing batch size: 8\n",
      "Warming up with 3 iterations...\n",
      "Running 10 timing iterations...\n",
      "Batch size 8:\n",
      "  Mean inference time: 0.0520s ¬± 0.0017s\n",
      "  FPS: 153.74\n",
      "  Min time: 0.0503s\n",
      "  Max time: 0.0560s\n",
      "\n",
      "Testing batch size: 16\n",
      "Warming up with 3 iterations...\n",
      "Running 10 timing iterations...\n",
      "Batch size 16:\n",
      "  Mean inference time: 0.1042s ¬± 0.0064s\n",
      "  FPS: 153.51\n",
      "  Min time: 0.0983s\n",
      "  Max time: 0.1205s\n",
      "\n",
      "Testing batch size: 32\n",
      "Warming up with 3 iterations...\n",
      "Running 10 timing iterations...\n",
      "Batch size 32:\n",
      "  Mean inference time: 0.1979s ¬± 0.0160s\n",
      "  FPS: 161.69\n",
      "  Min time: 0.1522s\n",
      "  Max time: 0.2169s\n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark test\n",
    "print(\"=\" * 60)\n",
    "print(\"DINOv3 INFERENCE SPEED BENCHMARK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test different batch sizes to find optimal throughput\n",
    "batch_sizes_to_test = [1, 2, 4, 8, 16, 32] if len(image_paths) >= 32 else [1, 2, 4, 8]\n",
    "\n",
    "results = benchmark_dinov3_inference(\n",
    "    processor=dv3_processor,\n",
    "    model=dv3_model,\n",
    "    image_paths=image_paths,\n",
    "    batch_sizes=batch_sizes_to_test,\n",
    "    num_warmup=3,\n",
    "    num_iterations=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results and provide recommendations\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BENCHMARK RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_fps = 0\n",
    "best_batch_size = 1\n",
    "target_fps = 30\n",
    "\n",
    "print(f\"{'Batch Size':<12} {'FPS':<8} {'Time (ms)':<12} {'Status':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for batch_size in sorted(results.keys()):\n",
    "    fps = results[batch_size]['fps']\n",
    "    time_ms = results[batch_size]['mean_time'] * 1000\n",
    "    status = \"‚úì TARGET MET\" if fps >= target_fps else \"‚úó Below target\"\n",
    "    \n",
    "    print(f\"{batch_size:<12} {fps:<8.2f} {time_ms:<12.2f} {status:<15}\")\n",
    "    \n",
    "    if fps > best_fps:\n",
    "        best_fps = fps\n",
    "        best_batch_size = batch_size\n",
    "\n",
    "print(f\"\\nBest performance: {best_fps:.2f} FPS with batch size {best_batch_size}\")\n",
    "\n",
    "if best_fps >= target_fps:\n",
    "    print(f\"üéâ SUCCESS: Achieved {best_fps:.2f} FPS (target: {target_fps} FPS)\")\n",
    "    print(f\"Recommended batch size: {best_batch_size}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: Best FPS ({best_fps:.2f}) is below target ({target_fps} FPS)\")\n",
    "    print(\"Consider:\")\n",
    "    print(\"  - Using a smaller/faster model (e.g., DINOv2-base instead of DINOv3-large)\")\n",
    "    print(\"  - Optimizing image preprocessing\")\n",
    "    print(\"  - Using model quantization\")\n",
    "    print(\"  - Running on a more powerful GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional optimization test: Compare DINOv2 vs DINOv3 performance\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DINOv2 vs DINOv3 COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test DINOv2 for comparison\n",
    "print(\"Testing DINOv2-base performance...\")\n",
    "processor_dv2, model_dv2 = load_dinov2_model()\n",
    "model_dv2 = model_dv2.to(device)\n",
    "\n",
    "# Quick test with batch size 1\n",
    "test_image = load_image(image_paths[0])\n",
    "times_dv2 = []\n",
    "\n",
    "print(\"Warming up DINOv2...\")\n",
    "for _ in range(3):\n",
    "    with torch.no_grad():\n",
    "        inputs = processor_dv2(images=test_image, return_tensors=\"pt\").to(device)\n",
    "        outputs = model_dv2(**inputs)\n",
    "\n",
    "print(\"Timing DINOv2...\")\n",
    "for _ in range(10):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        inputs = processor_dv2(images=test_image, return_tensors=\"pt\").to(device)\n",
    "        outputs = model_dv2(**inputs)\n",
    "    end_time = time.time()\n",
    "    times_dv2.append(end_time - start_time)\n",
    "\n",
    "dv2_fps = 1.0 / np.mean(times_dv2)\n",
    "dv2_time_ms = np.mean(times_dv2) * 1000\n",
    "\n",
    "print(f\"DINOv2-base: {dv2_fps:.2f} FPS ({dv2_time_ms:.2f} ms per image)\")\n",
    "print(f\"DINOv3-large: {results[1]['fps']:.2f} FPS ({results[1]['mean_time']*1000:.2f} ms per image)\")\n",
    "\n",
    "if dv2_fps >= target_fps:\n",
    "    print(f\"‚úÖ DINOv2-base meets target FPS ({target_fps})\")\n",
    "else:\n",
    "    print(f\"‚ùå DINOv2-base also below target FPS ({target_fps})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/home/milo/Documents/phd/VideoMimic/src/videomimic/data/example/0000.jpg\"\n",
    "image = load_image(url)\n",
    "features = extract_dinov2_features(image, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280)\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(image.size)\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280)\n",
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "url = \"/home/milo/Documents/phd/VideoMimic/src/videomimic/data/example/0000.jpg\"\n",
    "image = load_image(url)\n",
    "image_list = [image, image]\n",
    "features = extract_dinov3_features(image_list, dv3_processor, dv3_model)\n",
    "print(image.size)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_mimic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
